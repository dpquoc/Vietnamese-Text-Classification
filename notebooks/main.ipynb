{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-11-12T15:20:03.889920Z","iopub.status.busy":"2024-11-12T15:20:03.889508Z","iopub.status.idle":"2024-11-12T15:20:06.604296Z","shell.execute_reply":"2024-11-12T15:20:06.603138Z","shell.execute_reply.started":"2024-11-12T15:20:03.889880Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'Vietnamese-Text-Classification'...\n","remote: Enumerating objects: 31, done.\u001b[K\n","remote: Counting objects: 100% (31/31), done.\u001b[K\n","remote: Compressing objects: 100% (25/25), done.\u001b[K\n","remote: Total 31 (delta 4), reused 25 (delta 1), pack-reused 0 (from 0)\u001b[K\n","Receiving objects: 100% (31/31), 2.38 MiB | 4.62 MiB/s, done.\n","Resolving deltas: 100% (4/4), done.\n"]}],"source":["!git clone https://github.com/dpquoc/Vietnamese-Text-Classification"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-11-12T15:20:06.607363Z","iopub.status.busy":"2024-11-12T15:20:06.606951Z","iopub.status.idle":"2024-11-12T15:20:26.262162Z","shell.execute_reply":"2024-11-12T15:20:26.261171Z","shell.execute_reply.started":"2024-11-12T15:20:06.607316Z"},"trusted":true},"outputs":[],"source":["import os\n","import re\n","\n","from sklearn.model_selection import train_test_split\n","from typing import Optional, Union\n","import pandas as pd, numpy as np, torch\n","\n","from datasets import Dataset\n","from dataclasses import dataclass\n","\n","from transformers import AutoTokenizer\n","from transformers import EarlyStoppingCallback\n","from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n","from transformers import  AutoModelForSequenceClassification, TrainingArguments, Trainer\n","from torch.optim import AdamW"]},{"cell_type":"markdown","metadata":{},"source":["# Configs"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-11-12T15:20:26.264905Z","iopub.status.busy":"2024-11-12T15:20:26.264083Z","iopub.status.idle":"2024-11-12T15:20:26.271392Z","shell.execute_reply":"2024-11-12T15:20:26.270297Z","shell.execute_reply.started":"2024-11-12T15:20:26.264859Z"},"trusted":true},"outputs":[],"source":["CUR_DIR = os.getcwd()"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-11-12T15:20:26.273415Z","iopub.status.busy":"2024-11-12T15:20:26.273041Z","iopub.status.idle":"2024-11-12T15:20:26.311649Z","shell.execute_reply":"2024-11-12T15:20:26.310804Z","shell.execute_reply.started":"2024-11-12T15:20:26.273373Z"},"trusted":true},"outputs":[],"source":["USE_PEFT = False\n","FREEZE_LAYERS = 0 # NUMBER OF LAYERS TO FREEZE , DEBERTA LARGE HAS TOTAL OF 24 LAYERS\n","FREEZE_EMBEDDINGS = True # BOOLEAN TO FREEZE EMBEDDINGS\n","MAX_INPUT = 128 # LENGTH OF CONTEXT PLUS QUESTION ANSWER\n","# MODEL = 'deberta_w_phobert_embed' # HUGGING FACE MODEL\n","MODEL = 'vinai/phobert-base-v2' \n","TOKENIZER = f'{CUR_DIR}/Vietnamese-Text-Classification/tokenizer'"]},{"cell_type":"markdown","metadata":{},"source":["# Data Loader"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-11-12T15:20:26.314549Z","iopub.status.busy":"2024-11-12T15:20:26.314068Z","iopub.status.idle":"2024-11-12T15:20:26.357028Z","shell.execute_reply":"2024-11-12T15:20:26.356108Z","shell.execute_reply.started":"2024-11-12T15:20:26.314460Z"},"trusted":true},"outputs":[],"source":["train_data = pd.read_csv(f'{CUR_DIR}/Vietnamese-Text-Classification/data/train.csv')\n","valid_data = pd.read_csv(f'{CUR_DIR}/Vietnamese-Text-Classification/data/val.csv')"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-11-12T15:20:26.358388Z","iopub.status.busy":"2024-11-12T15:20:26.358091Z","iopub.status.idle":"2024-11-12T15:20:26.375929Z","shell.execute_reply":"2024-11-12T15:20:26.374934Z","shell.execute_reply.started":"2024-11-12T15:20:26.358357Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>content</th>\n","      <th>index_spans</th>\n","      <th>toxic</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>Dừa lắm :))</td>\n","      <td>[]</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>Bấp bênh vl thế</td>\n","      <td>[9, 10]</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>Chắc cũng biết ko tồn tại đc bao lâu nữa nên c...</td>\n","      <td>[53, 54, 55]</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>Thấy chán ad page này kiến thức thì nông cản c...</td>\n","      <td>[5, 6, 7, 8, 36, 37, 38, 39, 40, 41, 42, 43, 6...</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>Giang Giang Đỗ Thị Ngọc Hà trend mới kìa kìa</td>\n","      <td>[]</td>\n","      <td>False</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id                                            content  \\\n","0   0                                        Dừa lắm :))   \n","1   1                                    Bấp bênh vl thế   \n","2   2  Chắc cũng biết ko tồn tại đc bao lâu nữa nên c...   \n","3   3  Thấy chán ad page này kiến thức thì nông cản c...   \n","4   4       Giang Giang Đỗ Thị Ngọc Hà trend mới kìa kìa   \n","\n","                                         index_spans  toxic  \n","0                                                 []  False  \n","1                                            [9, 10]   True  \n","2                                       [53, 54, 55]   True  \n","3  [5, 6, 7, 8, 36, 37, 38, 39, 40, 41, 42, 43, 6...   True  \n","4                                                 []  False  "]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["train_data.head()"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-11-12T15:20:26.377738Z","iopub.status.busy":"2024-11-12T15:20:26.376948Z","iopub.status.idle":"2024-11-12T15:20:26.385913Z","shell.execute_reply":"2024-11-12T15:20:26.385022Z","shell.execute_reply.started":"2024-11-12T15:20:26.377705Z"},"trusted":true},"outputs":[],"source":["def preprocess(example):\n","    # Tokenize the 'content' (text) column\n","    tokenized_example = tokenizer(\"<s> \" + example['content'] + \"</s>\", truncation=True, max_length=128, padding='max_length')\n","    \n","    # Convert the 'toxic' column (True/False) into integer labels (1/0)\n","    tokenized_example['label'] = int(example['toxic'])\n","    \n","    return tokenized_example\n","\n","\n","@dataclass\n","class DataCollatorForClassification:\n","    tokenizer: PreTrainedTokenizerBase\n","    padding: Union[bool, str, PaddingStrategy] = True\n","    max_length: Optional[int] = None\n","    pad_to_multiple_of: Optional[int] = None\n","\n","    def __call__(self, input_batch):\n","        # Extract labels from the input batch\n","        labels = [example.pop('label') for example in input_batch]\n","\n","        # Tokenizer padding (make sure all sequences are the same length)\n","        batch = self.tokenizer.pad(\n","            input_batch,\n","            padding=self.padding,\n","            max_length=self.max_length,\n","            pad_to_multiple_of=self.pad_to_multiple_of,\n","            return_tensors='pt'  # Return tensors (PyTorch format)\n","        )\n","\n","        # Add labels to the batch\n","        batch['labels'] = torch.tensor(labels, dtype=torch.int64)\n","        \n","        return batch"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-11-12T15:20:31.492759Z","iopub.status.busy":"2024-11-12T15:20:31.492343Z","iopub.status.idle":"2024-11-12T15:20:31.658227Z","shell.execute_reply":"2024-11-12T15:20:31.657273Z","shell.execute_reply.started":"2024-11-12T15:20:31.492720Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["['<s>', 'xin', 'ch@@', 'à@@', 'o@@', ',', 'bạn', 'thế', 'nào', '?']\n","<s> xin chào, bạn thế nào ?\n"]}],"source":["tokenizer = AutoTokenizer.from_pretrained(f\"{CUR_DIR}/Vietnamese-Text-Classification/tokenizer\")\n","\n","# CHECK TOKENIZER\n","# Tokenize the text\n","tokens = tokenizer.tokenize(\"<s> xin chào, bạn thế nào ?\")\n","print(tokens)\n","\n","# Convert tokens back to string\n","decoded_text = tokenizer.decode(tokenizer.convert_tokens_to_ids(tokens))\n","print(decoded_text)\n","\n","## Save the tokenizer to a local folder\n","# tokenizer.save_pretrained(\"./tokenizer\")"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-11-12T15:20:34.143064Z","iopub.status.busy":"2024-11-12T15:20:34.142678Z","iopub.status.idle":"2024-11-12T15:20:34.211343Z","shell.execute_reply":"2024-11-12T15:20:34.210387Z","shell.execute_reply.started":"2024-11-12T15:20:34.143029Z"},"trusted":true},"outputs":[],"source":["train_dataset = Dataset.from_pandas(train_data)\n","valid_dataset = Dataset.from_pandas(valid_data)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-11-12T15:20:36.203437Z","iopub.status.busy":"2024-11-12T15:20:36.203053Z","iopub.status.idle":"2024-11-12T15:20:46.491353Z","shell.execute_reply":"2024-11-12T15:20:46.490431Z","shell.execute_reply.started":"2024-11-12T15:20:36.203394Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bbb45ebcc3ca4f3493f308b08341dbe0","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/8844 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"611018fcdab44c48aa9e77dd10b5eb6f","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/1106 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["train_tokenized_dataset = train_dataset.map(preprocess, remove_columns=['id', 'content', 'index_spans', 'toxic'])\n","valid_tokenized_dataset = valid_dataset.map(preprocess, remove_columns=['id', 'content', 'index_spans', 'toxic'])\n","\n","# train_tokenized_dataset.save_to_disk('train_tokenized_dataset')\n","# valid_tokenized_dataset.save_to_disk('valid_tokenized_dataset')"]},{"cell_type":"markdown","metadata":{},"source":["# Build Model"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-11-12T15:20:46.493619Z","iopub.status.busy":"2024-11-12T15:20:46.493218Z","iopub.status.idle":"2024-11-12T15:20:52.782504Z","shell.execute_reply":"2024-11-12T15:20:52.781701Z","shell.execute_reply.started":"2024-11-12T15:20:46.493582Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"eeb230ff99e7490d9f797dfa93c8d19d","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/678 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3dc2f5bccbd8422596b0a4444f34db59","version_major":2,"version_minor":0},"text/plain":["pytorch_model.bin:   0%|          | 0.00/540M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/phobert-base-v2 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n","tokenizer = AutoTokenizer.from_pretrained(TOKENIZER)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-11-12T15:20:52.783892Z","iopub.status.busy":"2024-11-12T15:20:52.783609Z","iopub.status.idle":"2024-11-12T15:20:52.789890Z","shell.execute_reply":"2024-11-12T15:20:52.788906Z","shell.execute_reply.started":"2024-11-12T15:20:52.783861Z"},"trusted":true},"outputs":[],"source":["if USE_PEFT:\n","    print('We are using PEFT.')\n","    from peft import LoraConfig, get_peft_model, TaskType\n","    peft_config = LoraConfig(\n","        r=8, lora_alpha=4, task_type=TaskType.SEQ_CLS, lora_dropout=0.1, \n","        bias=\"none\", inference_mode=False, \n","        target_modules=[\"query_proj\", \"value_proj\"],\n","        modules_to_save=['classifier','pooler'],\n","    )\n","    model = get_peft_model(model, peft_config)\n","    model.print_trainable_parameters()"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-11-12T15:20:52.792129Z","iopub.status.busy":"2024-11-12T15:20:52.791813Z","iopub.status.idle":"2024-11-12T15:20:52.802185Z","shell.execute_reply":"2024-11-12T15:20:52.801201Z","shell.execute_reply.started":"2024-11-12T15:20:52.792086Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Freezing embeddings.\n"]}],"source":["if FREEZE_EMBEDDINGS:\n","    print('Freezing embeddings.')\n","#     for param in model.deberta.embeddings.parameters():\n","    for param in model.roberta.embeddings.parameters():\n","\n","        param.requires_grad = False\n","if FREEZE_LAYERS>0:\n","    print(f'Freezing {FREEZE_LAYERS} layers.')\n","    for layer in model.deberta.encoder.layer[:FREEZE_LAYERS]:\n","        for param in layer.parameters():\n","            param.requires_grad = False"]},{"cell_type":"markdown","metadata":{},"source":["# Metric"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-11-12T15:20:52.803499Z","iopub.status.busy":"2024-11-12T15:20:52.803200Z","iopub.status.idle":"2024-11-12T15:20:52.811476Z","shell.execute_reply":"2024-11-12T15:20:52.810644Z","shell.execute_reply.started":"2024-11-12T15:20:52.803467Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import f1_score, accuracy_score\n","\n","def compute_metrics(p):\n","    # Get the predicted labels by taking the argmax over the logits\n","    predictions = np.argmax(p.predictions, axis=1)\n","    labels = p.label_ids\n","    \n","    # Compute F1 score (for binary classification)\n","    f1 = f1_score(labels, predictions, average=\"binary\")\n","    \n","    # Compute accuracy\n","    accuracy = accuracy_score(labels, predictions)\n","    \n","    return {\"f1\": f1, \"accuracy\": accuracy}\n"]},{"cell_type":"markdown","metadata":{},"source":["# Train and Save"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-11-12T15:20:52.812937Z","iopub.status.busy":"2024-11-12T15:20:52.812600Z","iopub.status.idle":"2024-11-12T15:20:52.903101Z","shell.execute_reply":"2024-11-12T15:20:52.902311Z","shell.execute_reply.started":"2024-11-12T15:20:52.812902Z"},"trusted":true},"outputs":[],"source":["# Define custom learning rate for embedding layer and other layers\n","\n","training_args = TrainingArguments(\n","    learning_rate=3e-5,  # Set base learning rate for other layers\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    num_train_epochs=2,\n","    report_to='none',\n","    output_dir='./checkpoints',\n","    overwrite_output_dir=True,\n","    fp16=True,\n","    gradient_accumulation_steps=1,\n","    logging_steps=150,\n","    eval_strategy='steps',\n","    eval_steps=150,\n","    save_strategy=\"steps\",\n","    save_steps=150,\n","    load_best_model_at_end=False,\n","    metric_for_best_model='accuracy',\n","    lr_scheduler_type='constant',  # Can use 'cosine' or 'linear' based on preference\n","    weight_decay=0.01,\n","    save_total_limit=2,\n",")\n","\n","# # Create the optimizer with parameter-specific learning rates\n","# def get_optimizer(model):\n","#     optimizer_params = [\n","#         {'params': model.deberta.embeddings.parameters(), 'lr': embedding_lr},  # Learning rate for embedding layer\n","#         {'params': model.deberta.encoder.parameters(), 'lr': other_lr},  # Learning rate for encoder layers\n","#         {'params': model.classifier.parameters(), 'lr': other_lr},  # Learning rate for the classifier\n","#     ]\n","#     return AdamW(optimizer_params, weight_decay=0.01)\n"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-11-12T15:20:55.932426Z","iopub.status.busy":"2024-11-12T15:20:55.932037Z","iopub.status.idle":"2024-11-12T15:20:56.270945Z","shell.execute_reply":"2024-11-12T15:20:56.269732Z","shell.execute_reply.started":"2024-11-12T15:20:55.932386Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n","  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"]}],"source":["trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    tokenizer=tokenizer,\n","    data_collator=DataCollatorForClassification(tokenizer=tokenizer),\n","    train_dataset=train_tokenized_dataset,\n","    eval_dataset=valid_tokenized_dataset,\n","    compute_metrics = compute_metrics,\n","#     optimizers=(get_optimizer(model), None)\n","    #callbacks=[EarlyStoppingCallback(early_stopping_patience=5)],\n",")\n"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-11-12T15:21:17.356859Z","iopub.status.busy":"2024-11-12T15:21:17.356463Z","iopub.status.idle":"2024-11-12T15:27:34.537532Z","shell.execute_reply":"2024-11-12T15:27:34.536675Z","shell.execute_reply.started":"2024-11-12T15:21:17.356826Z"},"trusted":true},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2212' max='2212' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2212/2212 06:13, Epoch 2/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>F1</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>150</td>\n","      <td>0.495900</td>\n","      <td>0.342996</td>\n","      <td>0.832487</td>\n","      <td>0.850814</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.385400</td>\n","      <td>0.302915</td>\n","      <td>0.867308</td>\n","      <td>0.875226</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.372400</td>\n","      <td>0.323963</td>\n","      <td>0.885553</td>\n","      <td>0.889693</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.356900</td>\n","      <td>0.414926</td>\n","      <td>0.842105</td>\n","      <td>0.861664</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.374700</td>\n","      <td>0.288019</td>\n","      <td>0.878002</td>\n","      <td>0.885172</td>\n","    </tr>\n","    <tr>\n","      <td>900</td>\n","      <td>0.334400</td>\n","      <td>0.306521</td>\n","      <td>0.892532</td>\n","      <td>0.893309</td>\n","    </tr>\n","    <tr>\n","      <td>1050</td>\n","      <td>0.343900</td>\n","      <td>0.314579</td>\n","      <td>0.889693</td>\n","      <td>0.889693</td>\n","    </tr>\n","    <tr>\n","      <td>1200</td>\n","      <td>0.290300</td>\n","      <td>0.361345</td>\n","      <td>0.878906</td>\n","      <td>0.887884</td>\n","    </tr>\n","    <tr>\n","      <td>1350</td>\n","      <td>0.248200</td>\n","      <td>0.358582</td>\n","      <td>0.888483</td>\n","      <td>0.889693</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.280600</td>\n","      <td>0.362647</td>\n","      <td>0.891221</td>\n","      <td>0.896926</td>\n","    </tr>\n","    <tr>\n","      <td>1650</td>\n","      <td>0.243400</td>\n","      <td>0.421913</td>\n","      <td>0.891386</td>\n","      <td>0.895118</td>\n","    </tr>\n","    <tr>\n","      <td>1800</td>\n","      <td>0.294200</td>\n","      <td>0.287665</td>\n","      <td>0.891791</td>\n","      <td>0.895118</td>\n","    </tr>\n","    <tr>\n","      <td>1950</td>\n","      <td>0.283700</td>\n","      <td>0.289143</td>\n","      <td>0.897317</td>\n","      <td>0.899638</td>\n","    </tr>\n","    <tr>\n","      <td>2100</td>\n","      <td>0.260200</td>\n","      <td>0.411737</td>\n","      <td>0.886972</td>\n","      <td>0.881555</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["trainer.train()\n","trainer.save_model(f'trained_model')"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-11-12T15:28:34.967758Z","iopub.status.busy":"2024-11-12T15:28:34.966920Z","iopub.status.idle":"2024-11-12T15:28:35.000220Z","shell.execute_reply":"2024-11-12T15:28:34.999040Z","shell.execute_reply.started":"2024-11-12T15:28:34.967715Z"},"trusted":true},"outputs":[],"source":["torch.cuda.empty_cache()"]},{"cell_type":"markdown","metadata":{},"source":["# Test Saved Model"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-11-12T15:28:38.575271Z","iopub.status.busy":"2024-11-12T15:28:38.574452Z","iopub.status.idle":"2024-11-12T15:28:38.736062Z","shell.execute_reply":"2024-11-12T15:28:38.735068Z","shell.execute_reply.started":"2024-11-12T15:28:38.575231Z"},"trusted":true},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained(TOKENIZER)"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-11-12T15:28:40.139321Z","iopub.status.busy":"2024-11-12T15:28:40.138134Z","iopub.status.idle":"2024-11-12T15:28:40.227301Z","shell.execute_reply":"2024-11-12T15:28:40.226493Z","shell.execute_reply.started":"2024-11-12T15:28:40.139246Z"},"trusted":true},"outputs":[],"source":["if USE_PEFT:\n","    model = AutoModelForSequenceClassification.from_pretrained(f'{CUR_DIR}/trained_model')\n","    model = get_peft_model(model, peft_config)\n","else:\n","    model = AutoModelForSequenceClassification.from_pretrained(f'{CUR_DIR}/trained_model')"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-11-12T15:28:42.899433Z","iopub.status.busy":"2024-11-12T15:28:42.898546Z","iopub.status.idle":"2024-11-12T15:28:43.108408Z","shell.execute_reply":"2024-11-12T15:28:43.107532Z","shell.execute_reply.started":"2024-11-12T15:28:42.899375Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n","  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"]}],"source":["training_args = TrainingArguments(\n","    learning_rate=3e-5,  # Set base learning rate for other layers\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    num_train_epochs=2,\n","    report_to='none',\n","    output_dir='./checkpoints',\n","    overwrite_output_dir=True,\n","    fp16=True,\n","    gradient_accumulation_steps=1,\n","    logging_steps=150,\n","    eval_strategy='steps',\n","    eval_steps=150,\n","    save_strategy=\"steps\",\n","    save_steps=150,\n","    load_best_model_at_end=False,\n","    metric_for_best_model='accuracy',\n","    lr_scheduler_type='constant',  # Can use 'cosine' or 'linear' based on preference\n","    weight_decay=0.01,\n","    save_total_limit=2,\n",")\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    tokenizer=tokenizer,\n","    data_collator=DataCollatorForClassification(tokenizer=tokenizer),\n","    compute_metrics = compute_metrics,\n","#     optimizers=(get_optimizer(model), None)\n","    #callbacks=[EarlyStoppingCallback(early_stopping_patience=5)],\n",")\n"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-11-12T15:28:52.706477Z","iopub.status.busy":"2024-11-12T15:28:52.706086Z","iopub.status.idle":"2024-11-12T15:28:56.087348Z","shell.execute_reply":"2024-11-12T15:28:56.086406Z","shell.execute_reply.started":"2024-11-12T15:28:52.706440Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6cdfbce3c2214517946cf0c89d46f744","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/1106 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["test_data = pd.read_csv(f'{CUR_DIR}/Vietnamese-Text-Classification/data/test.csv')\n","test_dataset = Dataset.from_pandas(test_data)\n","test_tokenized_dataset = test_dataset.map(preprocess, remove_columns=['id', 'content', 'index_spans', 'toxic'])"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-11-12T15:28:58.082604Z","iopub.status.busy":"2024-11-12T15:28:58.081819Z","iopub.status.idle":"2024-11-12T15:29:03.319244Z","shell.execute_reply":"2024-11-12T15:29:03.318287Z","shell.execute_reply.started":"2024-11-12T15:28:58.082558Z"},"trusted":true},"outputs":[{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Accuracy:  0.9014466546112115\n","F1:  0.8948891031822565\n"]}],"source":["test_predictions = trainer.predict(test_tokenized_dataset)\n","res = compute_metrics(test_predictions)\n","print('Accuracy: ', res['accuracy'])\n","print('F1: ', res['f1'])"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30786,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
